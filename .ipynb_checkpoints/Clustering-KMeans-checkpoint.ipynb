{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP1: GATHER THE DATA\n",
    "- Use Selenium/BeautifulSoup to webscrape CARDNAME|CARDTEXT|FACTION(S), then store in csv or xls.\n",
    "OR\n",
    "- Find somebody's already made excel with card and text details.\n",
    "STEP2: REMOVE STOPWORDS AND PERFORM K-MEANS ALG. ON CARDTEXT\n",
    "- Initially I wanted to group the factions, THEN cluster on the text, but for the first run we will cluster on just the text.\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "%matplotlib inline\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# import json\n",
    "import warnings\n",
    "import mechanicalsoup\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ITERATE THROUGH EACH PAGE AND GRAB Each card, go to its page, grab its flavor text + faction(s).\n",
    "(All this really does is save you time by not having to go into ->\"Deck Builder\" and\n",
    "add ALL your cards to a deck and exporting it.... :))\n",
    "\"\"\"\n",
    "df = pd.DataFrame(columns=['name', 'faction', 'rarity', 'text', 'shiftstone_cost', 'decks_on_site'])\n",
    "page_num = 1\n",
    "check_last_pg = re.compile(r'\\b(No cards found in your collection)\\b')\n",
    "final_collection = []\n",
    "browser = mechanicalsoup.Browser(soup_config={'features': 'lxml'})\n",
    "\n",
    "while True:\n",
    "    # Now that were logged in pull each link for our collection and grab the info\n",
    "    current_page = 'https://eternalwarcry.com/cards?p=' + str(page_num)\n",
    "    page_num = page_num + 1 # Iterate don't wanna forget ;)\n",
    "    collection_page = browser.get(current_page) # Response object with .soup object\n",
    "    \n",
    "    # Get out of loop if we reach 'no cards exists' page.\n",
    "    if bool(check_last_pg.search(collection_page.text)):\n",
    "        break\n",
    "    \n",
    "    # Current Page. #collection_page.text because its response object\n",
    "    html_page = collection_page.soup \n",
    "    # Get all cards on this page.\n",
    "    divs = html_page.findAll(class_= 'card-search-item col-lg-3 col-sm-4 col-xs-6 add-card-main element-relative')  \n",
    "    for div in divs:\n",
    "        # This is where it gets fun. \n",
    "        # Each div is a card from the search_view. a href has the link which contains info.\n",
    "        card_name = str(div.find_all('a'))\n",
    "        #print(card_name) # This is to be searched for the name of card; can also acquire set and card#\n",
    "        card_details = str(div.find(class_ = 'display-count'))\n",
    "\n",
    "        # STEP TWO: FORMULATE CARD\n",
    "        # First part of string is count\n",
    "        count = str(re.search(r'data-count=\"(\\d)\"', card_details, re.IGNORECASE).group(1))\n",
    "\n",
    "        # Now get set - card#\n",
    "        card_set = str(re.search(r'data-card=\"(\\d+-\\d+)\"', card_details, re.IGNORECASE).group(1))\n",
    "        card_set = card_set.split('-')\n",
    "        details = '(Set' + str(card_set[0]) + ' #' + str(card_set[1]) + ')'\n",
    "\n",
    "        # Now get card name with grammar\n",
    "        name = str(re.search(r'<img alt=\"(.+)\" class=', card_name, re.IGNORECASE).group(1))\n",
    "\n",
    "        # Put it altogether....\n",
    "        item = count + ' ' + name + ' ' + details\n",
    "        #print(item)\n",
    "\n",
    "        # Drop each page into a list for later...\n",
    "        final_collection.append(item)\n",
    "        \n",
    "        \n",
    "# TODO: ADD SHIFSTONE AMOUNT TO MY_COLLECTION FOR BETTER ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many total cards we have (all 4 of each specific card).\n",
    "total_cards = 0\n",
    "for x in final_collection:\n",
    "    total_cards = total_cards + int(x[0])\n",
    "total_cards\n",
    "\n",
    "output_json = {'total_cards': total_cards, 'my_collection': final_collection}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all cards to JSON or csv + excel.\n",
    "# with open('my_collection.json', 'w') as fp:\n",
    "#     json.dump(output_json, fp)\n",
    "full_all_card = pd.to_excel('all_cards.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
